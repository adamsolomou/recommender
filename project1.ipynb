{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Project1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "9fnJbFSP1G_C",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "cJHUqlKhNQfa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3gsa7tZ8PDI6",
        "colab_type": "code",
        "outputId": "25056a75-b8ad-4c87-9651-a9c1cddeb8d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        }
      },
      "cell_type": "code",
      "source": [
        "# Tensorboard in Colab environment.\n",
        "!pip install tensorboardcolab\n",
        "from tensorboardcolab import *\n",
        "tbc = TensorBoardColab()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorboardcolab in /usr/local/lib/python3.6/dist-packages (0.0.22)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Wait for 8 seconds...\n",
            "TensorBoard link:\n",
            "https://e61f6b25.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "YzFxqDczPKOw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Provide the ground truth last word as input to the RNN, not the last word you predicted. This is common practice.\n",
        "# do this only in the train phase not the validation right?\n",
        "\n",
        "# what to do with ''' in sentences ???"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "prVU94BKqwfe",
        "colab_type": "code",
        "outputId": "8c8ee883-0ce9-4447-f6a7-c16386133100",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Fn2Ro8PorFkE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aMcREkcOrGLg",
        "colab_type": "code",
        "outputId": "6f622491-e976-447b-9d2b-a29e6b18799f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "cI9jNorj0m2t",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "base_folder = '/gdrive/My Drive/Colab Notebooks/NLU/data/'\n",
        "\n",
        "sentence_length = 30"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jHNS3Lh2uHtO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def preprocess_sentences(sentence):\n",
        "  tokens = sentence.split(\" \")[:-1]\n",
        "  sentece_length_no_bos_eos = sentence_length - 2\n",
        "  tokenized_sentence = ['<bos>'] + tokens[:sentece_length_no_bos_eos] + ['<pad>'] * (sentece_length_no_bos_eos - len(tokens)) + ['<eos>']\n",
        "  return tokenized_sentence\n",
        "\n",
        "def get_sentences_from_file(file_name, maximum_number_of_sentences=-1):\n",
        "  fp = open(base_folder + file_name)\n",
        "  irofile = iter(fp)\n",
        "  \n",
        "  sentences = []\n",
        "  for line in irofile:\n",
        "    if maximum_number_of_sentences <= 0:\n",
        "      break\n",
        "    maximum_number_of_sentences -= 1\n",
        "    sentences.append(preprocess_sentences(line))\n",
        "    \n",
        "  fp.close()\n",
        "  return sentences"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GCF7RHddrGOJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sentences_train = get_sentences_from_file('sentences.train', maximum_number_of_sentences=10000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "d5pk6A593Rqe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ct248ho81Jps",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## create LSTM"
      ]
    },
    {
      "metadata": {
        "id": "Itaph2ITxd1H",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def del_all_flags(FLAGS):\n",
        "    flags_dict = FLAGS._flags()    \n",
        "    keys_list = [keys for keys in flags_dict]    \n",
        "    for keys in keys_list:\n",
        "        FLAGS.__delattr__(keys)\n",
        "\n",
        "del_all_flags(tf.flags.FLAGS)\n",
        "\n",
        "log_dir = \"/tmp/tensorflow/mnist_cnn/logs\"\n",
        "tf.app.flags.DEFINE_string(\"log_dir\", log_dir, \"Summaries log directory\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "08e0bQXuxEWa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def variable_summaries(var):\n",
        "  \"\"\"Attach a lot of summaries to a Tensor for TensorBoard visualizations.\"\"\"\n",
        "  mean = tf.reduce_mean(var)\n",
        "  tf.summary.scalar('mean', mean)\n",
        "  with tf.name_scope('stddev'):\n",
        "      stddev = tf.sqrt(tf.reduce_mean(tf.square(var - mean)))\n",
        "  tf.summary.scalar('stddev', stddev)\n",
        "  tf.summary.scalar('max', tf.reduce_max(var))\n",
        "  tf.summary.scalar('min', tf.reduce_min(var))\n",
        "  tf.summary.histogram('histogram', var)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Pe2ZdbuD3DMz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def get_vocabulary_size(sentences):\n",
        "  vocabulary = set()\n",
        "  for word in np.array(sentences).flatten():\n",
        "    vocabulary.add(word)\n",
        "    \n",
        "  vocabulary.add('<bos>')\n",
        "  vocabulary.add('<eos>')\n",
        "  vocabulary.add('<pad>')\n",
        "  vocabulary.add('<unk>')\n",
        "  \n",
        "  word2number_mapping = dict([(y,x) for x,y in enumerate(sorted(vocabulary))])\n",
        "  number2word_mapping = dict([(x,y) for x,y in enumerate(sorted(vocabulary))])\n",
        "  \n",
        "  return word2number_mapping, number2word_mapping, len(vocabulary)\n",
        "\n",
        "\n",
        "word2number_mapping, number2word_mapping, vocabulary_size = get_vocabulary_size(sentences_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8IuF9fLT5_3l",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def sentences2vec(sentences, word2number_mapping):\n",
        "  sentence_vectors = []\n",
        "  for sentence in sentences:\n",
        "    sentence_vectors.append([word2number_mapping[word] for word in sentence])\n",
        "  return sentence_vectors\n",
        "\n",
        "sentence_vectors_train = sentences2vec(sentences_train, word2number_mapping)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4ZNSTe0f3xNF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "embedding_size = 100\n",
        "hidden_state_size = 512"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kA8_PV_oCNBu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hod4MMq1y4cu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def compute_equations(weights_i, weights_f, weights_o, weights_g, concatenated_input, c):\n",
        "  concatenated_input = tf.reshape(concatenated_input, [-1, 1])\n",
        "  i = tf.sigmoid(tf.matmul(weights_i, concatenated_input, name='matmul_i'), name='calculation_i')\n",
        "  f = tf.sigmoid(tf.matmul(weights_f, concatenated_input, name='matmul_f'), name='calculation_f')\n",
        "  o = tf.sigmoid(tf.matmul(weights_o, concatenated_input, name='matmul_o'), name='calculation_o')\n",
        "  g = tf.tanh(tf.matmul(weights_g, concatenated_input, name='matmul_g'), name='calculation_g')\n",
        "  \n",
        "  c = tf.multiply(f, c) + tf.multiply(i, g)\n",
        "  h = np.multiply(o, tf.tanh(c))\n",
        "  \n",
        "  return i, f, o, g, c, h\n",
        "  \n",
        "def weight_variable(shape, name):\n",
        "  # todo , initializer=tf.contrib.layers.xavier_initializer()\n",
        "  return tf.Variable(tf.truncated_normal(shape, stddev=0.1), name=name)\n",
        "\n",
        "def LSTM():\n",
        "  input_sentence = tf.placeholder(tf.int32, shape=[sentence_length], name='input_sentence')\n",
        "  output_sentence = tf.placeholder(tf.int32, shape=[sentence_length - 1], name='output_sentence')\n",
        "  \n",
        "  input_embeddings = weight_variable([vocabulary_size, embedding_size], name='input_embeddings')\n",
        "  \n",
        "  sentence_embedding = tf.nn.embedding_lookup(input_embeddings, input_sentence, name='sentence_embedding')\n",
        "  \n",
        "#   print(sentence_embedding.eval())\n",
        "   \n",
        "  # compute functions i, f, o, g as in https://arxiv.org/pdf/1409.2329.pdf\n",
        "  weights_i = weight_variable([hidden_state_size, hidden_state_size + embedding_size + 1], name='weights_i')\n",
        "#   variable_summaries(weights_i)\n",
        "  weights_f = weight_variable([hidden_state_size, hidden_state_size + embedding_size + 1], name='weights_f')\n",
        "#   variable_summaries(weights_f)\n",
        "  weights_o = weight_variable([hidden_state_size, hidden_state_size + embedding_size + 1], name='weights_o')\n",
        "#   variable_summaries(weights_o)\n",
        "  weights_g = weight_variable([hidden_state_size, hidden_state_size + embedding_size + 1], name='weights_g')\n",
        "#   variable_summaries(weights_g)\n",
        "  \n",
        "  weights_output = weight_variable([vocabulary_size, hidden_state_size], name='weights_output')\n",
        "  \n",
        "  hidden_state = tf.zeros([hidden_state_size], tf.float32)\n",
        "#   tf.summary.histogram('hidden_state', hidden_state)\n",
        "  \n",
        "  c = tf.zeros([hidden_state_size, 1], tf.float32)\n",
        "#   tf.summary.histogram('c', c)\n",
        "  \n",
        "  outputs = []\n",
        "  for i in range(sentence_length - 1):\n",
        "    input_t = sentence_embedding[i]\n",
        "  \n",
        "    concatenated_input = tf.concat([tf.reshape(hidden_state, [-1]), tf.cast(input_t, tf.float32), [1.0]], 0)\n",
        "    \n",
        "    i, f, o, g, c, hidden_state = compute_equations(weights_i, weights_f, weights_o, weights_g, concatenated_input, c)\n",
        "    \n",
        "    output_t = tf.reshape(tf.matmul(weights_output, hidden_state, name='matmul_output'), [-1])\n",
        "    \n",
        "    outputs.append(output_t)\n",
        "    \n",
        "  cross_entropy_loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=outputs, labels=output_sentence))\n",
        "  \n",
        "  output_probabilities = tf.nn.softmax(outputs)\n",
        "  \n",
        "  return input_sentence, output_sentence, outputs, cross_entropy_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hmPFx65zLeZ5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fHmsrPpFGO3o",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# counter = 0\n",
        "\n",
        "# def senteces2vec_to_categorical(sentence_vector):\n",
        "#   sentence_to_categorical = np.zeros((sentence_length - 1, vocabulary_size))\n",
        "\n",
        "#   for i in range(sentence_length - 1):\n",
        "#     sentence_to_categorical[i, sentence_vector[i]] = 1\n",
        "      \n",
        "#   return sentence_to_categorical\n",
        "\n",
        "def get_sentence(sentence_vectors_train, pos):\n",
        "  sentence_vector = sentence_vectors_train[pos]\n",
        "  #labels = senteces2vec_to_categorical(sentence_vector)\n",
        "  \n",
        "  return sentence_vector, sentence_vector[1:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SjnwjtpUzO7L",
        "colab_type": "code",
        "outputId": "b38dcdde-0460-4007-e64e-505bac5c2c35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "cell_type": "code",
      "source": [
        "sentence_vector, labels = get_sentence(sentence_vectors_train, 0)\n",
        "np.array(sentence_vector)"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 151,  158, 5156,   77, 7035, 4715,  597, 5165, 4099, 6923,   94,\n",
              "       6917, 3812, 7035, 6064, 6539, 4839,  597,  110,  153,  153,  153,\n",
              "        153,  153,  153,  153,  153,  153,  153,  152])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "metadata": {
        "id": "hol8cAYKJuvl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xzcWvnQWJqtK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        },
        "outputId": "2fd779c8-7783-46a4-ae0b-1f444008983a"
      },
      "cell_type": "code",
      "source": [
        "with tf.Session() as session:\n",
        "  input_sentence, output_sentence, output_probs, loss = LSTM()\n",
        "  \n",
        "  optimizer = tf.train.AdamOptimizer().minimize(loss)\n",
        "#   optimizer = tf.train.AdamOptimizer()\n",
        "#   gvs = optimizer.compute_gradients(loss)\n",
        "#   capped_gvs = [(tf.clip_by_value(grad, -5., 5.), var) for grad, var in gvs]\n",
        "#   train_op = optimizer.apply_gradients(capped_gvs)\n",
        "  \n",
        "  session.run(tf.global_variables_initializer())\n",
        "  \n",
        "  \n",
        "  n_epochs = 10\n",
        "  for epoch in range(n_epochs):\n",
        "    \n",
        "    loss_epoch = 0\n",
        "    \n",
        "    test_size = 100\n",
        "    for pos in range(test_size):\n",
        "      sentence_vector, labels = get_sentence(sentence_vectors_train, pos)\n",
        "\n",
        "      loss_sample, _ = session.run([loss, optimizer], feed_dict={input_sentence: sentence_vector, output_sentence: labels})\n",
        "    \n",
        "      loss_epoch += loss_sample\n",
        "      \n",
        "    loss_epoch /= test_size\n",
        "    print(f'epoch: {epoch:3d} loss: {loss_epoch:.4f}')"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch:   0 loss: 3.7365\n",
            "epoch:   1 loss: 2.4521\n",
            "epoch:   2 loss: 2.2366\n",
            "epoch:   3 loss: 2.1029\n",
            "epoch:   4 loss: 2.0013\n",
            "epoch:   5 loss: 1.8753\n",
            "epoch:   6 loss: 1.7603\n",
            "epoch:   7 loss: 1.6652\n",
            "epoch:   8 loss: 1.5369\n",
            "epoch:   9 loss: 1.3941\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "A0F0lBcsLKuk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# saver = tf.train.Saver() \n",
        "# saver.save(sess, 'filename.chkp')\n",
        "\n",
        "# Then you'll be able to access the model:\n",
        "\n",
        "# sess = tf.Session()\n",
        "# saver = tf.train.Saver()\n",
        "# saver.restore(sess, 'filename.chkp')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vh-jGyVeFSUu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "outputId": "91f258f2-abb8-4432-e855-46b725d287cb"
      },
      "cell_type": "code",
      "source": [
        "k = 1\n",
        "for i in b[0]:\n",
        "  prediction = np.argmax(i)\n",
        "  print(f'Prediction: {number2word_mapping[prediction]:10s} correct word: {number2word_mapping[sentence_vector[k]]}')\n",
        "  k += 1"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prediction: ``         correct word: ``\n",
            "Prediction: i          correct word: i\n",
            "Prediction: 've        correct word: 've\n",
            "Prediction: never      correct word: never\n",
            "Prediction: had        correct word: had\n",
            "Prediction: any        correct word: any\n",
            "Prediction: ice-cream  correct word: ice-cream\n",
            "Prediction: for        correct word: for\n",
            "Prediction: myself     correct word: myself\n",
            "Prediction: ,          correct word: ,\n",
            "Prediction: my         correct word: my\n",
            "Prediction: father     correct word: father\n",
            "Prediction: never      correct word: never\n",
            "Prediction: let        correct word: let\n",
            "Prediction: me         correct word: me\n",
            "Prediction: have       correct word: have\n",
            "Prediction: any        correct word: any\n",
            "Prediction: .          correct word: .\n",
            "Prediction: <pad>      correct word: <pad>\n",
            "Prediction: <pad>      correct word: <pad>\n",
            "Prediction: <pad>      correct word: <pad>\n",
            "Prediction: <pad>      correct word: <pad>\n",
            "Prediction: <pad>      correct word: <pad>\n",
            "Prediction: <pad>      correct word: <pad>\n",
            "Prediction: <pad>      correct word: <pad>\n",
            "Prediction: <pad>      correct word: <pad>\n",
            "Prediction: <pad>      correct word: <pad>\n",
            "Prediction: <pad>      correct word: <pad>\n",
            "Prediction: <eos>      correct word: <eos>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "IxjVQDHm9pOP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "0be4f400-6dec-4fda-ea01-b5dd83585969"
      },
      "cell_type": "code",
      "source": [
        "with tf.Session() as session:\n",
        "  a = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=np.array([[1,2,3],[1,2,3]], dtype=np.float32), labels=[0,2])\n",
        "  print(a.eval())"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2.407606   0.40760598]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ZzNWxi-z9pQv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "outputId": "a0fb6466-7f90-4e5f-dd3d-bc327b6d00b1"
      },
      "cell_type": "code",
      "source": [
        "sentence_vector, labels = get_sentence(sentence_vectors_train)\n",
        "sentence_vector[1:]"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[158,\n",
              " 5156,\n",
              " 77,\n",
              " 7035,\n",
              " 4715,\n",
              " 597,\n",
              " 5165,\n",
              " 4099,\n",
              " 6923,\n",
              " 94,\n",
              " 6917,\n",
              " 3812,\n",
              " 7035,\n",
              " 6064,\n",
              " 6539,\n",
              " 4839,\n",
              " 597,\n",
              " 110,\n",
              " 153,\n",
              " 153,\n",
              " 153,\n",
              " 153,\n",
              " 153,\n",
              " 153,\n",
              " 153,\n",
              " 153,\n",
              " 153,\n",
              " 153,\n",
              " 152]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "metadata": {
        "id": "XUPgU-_U9pTf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OOwc0njgyBCi",
        "colab_type": "code",
        "outputId": "65d42319-fb33-45f3-9681-c9dc995901a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "cell_type": "code",
      "source": [
        "# Create the session\n",
        "tf.reset_default_graph()\n",
        "sess.close()\n",
        "sess = tf.InteractiveSession()\n",
        "\n",
        "# Tensorboard\n",
        "train_writer = tbc.get_deep_writers(\"single_layer_model/train\")\n",
        "train_writer.add_graph(sess.graph)\n",
        "valid_writer = tbc.get_deep_writers(\"single_layer_model/valid\")\n",
        "valid_writer.add_graph(sess.graph)\n",
        "\n",
        "# Initialize all variables\n",
        "sess.run(tf.global_variables_initializer())\n",
        "\n",
        "# To be able to see something in tensorboard, we must merge summaries to one common operation.\n",
        "# Whenever we want to write summaries, we must request this operation from the graph.\n",
        "# Note: creating the file writers should happen after the session was launched.\n",
        "summaries_merged = tf.summary.merge_all()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py:1702: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
            "  warnings.warn('An interactive session is already active. This can '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "9NDvUefSyEI3",
        "colab_type": "code",
        "outputId": "e569c5c1-e97f-4bc0-ff35-77b0f4f467ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2789
        }
      },
      "cell_type": "code",
      "source": [
        "run(sess)\n",
        "train_writer.flush()\n",
        "valid_writer.flush()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: You must feed a value for placeholder tensor 'input_sentence' with dtype int32 and shape [30]\n\t [[{{node input_sentence}}]]\n\t [[{{node MatMul_4}}]]",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-233-a073a337dbd6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtrain_writer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mvalid_writer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-231-42fdc544f46d>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(session)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0minput_sentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_sentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdamOptimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mgvs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-228-f3d32d48908a>\u001b[0m in \u001b[0;36mLSTM\u001b[0;34m()\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0moutput_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m     \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, feed_dict, session)\u001b[0m\n\u001b[1;32m    693\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m     \"\"\"\n\u001b[0;32m--> 695\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_eval_using_default_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    697\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_eval_using_default_session\u001b[0;34m(tensors, feed_dict, graph, session)\u001b[0m\n\u001b[1;32m   5179\u001b[0m                        \u001b[0;34m\"the tensor's graph is different from the session's \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5180\u001b[0m                        \"graph.\")\n\u001b[0;32m-> 5181\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1346\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1350\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: You must feed a value for placeholder tensor 'input_sentence' with dtype int32 and shape [30]\n\t [[node input_sentence (defined at <ipython-input-228-f3d32d48908a>:18) ]]\n\t [[node MatMul_4 (defined at <ipython-input-228-f3d32d48908a>:53) ]]\n\nCaused by op 'input_sentence', defined at:\n  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.6/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-233-a073a337dbd6>\", line 1, in <module>\n    run(sess)\n  File \"<ipython-input-231-42fdc544f46d>\", line 2, in run\n    input_sentence, output_sentence, outputs, loss = LSTM()\n  File \"<ipython-input-228-f3d32d48908a>\", line 18, in LSTM\n    input_sentence = tf.placeholder(tf.int32, shape=[sentence_length], name='input_sentence')\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/array_ops.py\", line 2077, in placeholder\n    return gen_array_ops.placeholder(dtype=dtype, shape=shape, name=name)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_array_ops.py\", line 5791, in placeholder\n    \"Placeholder\", dtype=dtype, shape=shape, name=name)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 3300, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 1801, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'input_sentence' with dtype int32 and shape [30]\n\t [[node input_sentence (defined at <ipython-input-228-f3d32d48908a>:18) ]]\n\t [[node MatMul_4 (defined at <ipython-input-228-f3d32d48908a>:53) ]]\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "JHGKIL59yELJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DFhIzmucyEPj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0wSz4r8wJux0",
        "colab_type": "code",
        "outputId": "df7c8ba5-00cb-4299-8d60-a0beb91ae2d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "t1 = [1,2,3]\n",
        "t2 = [2,3,4]\n",
        "\n",
        "\n",
        "t3 = tf.multiply(t1, t2) + tf.multiply(t1, t2) \n",
        "t3.eval()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 4, 12, 24], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 136
        }
      ]
    },
    {
      "metadata": {
        "id": "AeXDoCNpwkYE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_TPWSmORynl3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "session.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6I6XMca_ynom",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TD1oePdUIGIG",
        "colab_type": "code",
        "outputId": "1f5b57e2-78b1-40cb-c154-a17bbd2d8f24",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        }
      },
      "cell_type": "code",
      "source": [
        "sentence_to_categorical.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-994a5a248fd9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msentence_to_categorical\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'sentence_to_categorical' is not defined"
          ]
        }
      ]
    }
  ]
}